I"r<p>Cloudflare raw logs is enterprise only.
Enterprise customers should use <a href="https://developers.cloudflare.com/logs/logpull-api/enabling-log-retention/">this API</a> to enable Cloudflare log retention. That said, once this API is used, CF will start logging and it’s not on by default.</p>

<p>This simple bash script will periodically pull every field in Cloudflare raw logs using API. Below fields should be adjusted per your needs.</p>
<ul>
  <li><code class="highlighter-rouge">GAP</code> : here you define when to start pulling logs. In this example we are starting from 5m(300s) ago from current timestamp.</li>
  <li><code class="highlighter-rouge">INTERVAL</code> : here you define how often you want to pull logs. In this particular example, the script will work to get logs for 60s(1m).</li>
  <li><code class="highlighter-rouge">yourzone</code> : replace this with your zoneId that can be found in the dashboard.</li>
  <li><code class="highlighter-rouge">youremail</code> : replace this with your email address for Cloudflare dashboard.</li>
  <li><code class="highlighter-rouge">yourapikey</code> : replace this with your glabal api key for the email.</li>
</ul>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1">#!/bin/bash</span>
  
<span class="no">TIME</span><span class="o">=</span><span class="sb">`date +%s`</span> <span class="c1">#get current time</span>
<span class="no">GAP</span><span class="o">=</span><span class="mi">240</span>         <span class="c1">#set gap for getting log</span>
<span class="no">INTERVAL</span><span class="o">=</span><span class="mi">60</span>     <span class="c1">#set logging interval</span>

<span class="no">ZONE_ID</span><span class="o">=</span><span class="n">yourzone</span> 
<span class="no">ADMIN_ID</span><span class="o">=</span><span class="n">youremail</span> 
<span class="no">API_KEY</span><span class="o">=</span><span class="n">yourapikey</span>

  <span class="n">curl</span> <span class="o">-</span><span class="n">svo</span> <span class="s2">"$TIME.json"</span> <span class="o">-</span><span class="no">X</span> <span class="no">GET</span> <span class="s2">"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/logs/received?start=`expr $TIME - $GAP - $INTERVAL`&amp;end=`expr $TIME - $GAP`&amp;timestamps=rfc3339&amp;fields=$(curl -s -H "</span><span class="no">X</span><span class="o">-</span><span class="no">Auth</span><span class="o">-</span><span class="no">Email</span><span class="p">:</span> <span class="vg">$AUTH_EMAIL</span><span class="s2">" -H "</span><span class="no">X</span><span class="o">-</span><span class="no">Auth</span><span class="o">-</span><span class="no">Key</span><span class="p">:</span> <span class="vg">$API_KEY</span><span class="s2">" "</span><span class="n">https</span><span class="ss">:/</span><span class="o">/</span><span class="n">api</span><span class="p">.</span><span class="nf">cloudflare</span><span class="p">.</span><span class="nf">com</span><span class="o">/</span><span class="n">client</span><span class="o">/</span><span class="n">v4</span><span class="o">/</span><span class="n">zones</span><span class="o">/</span><span class="vg">$ZONE_ID</span><span class="o">/</span><span class="n">logs</span><span class="o">/</span><span class="n">received</span><span class="o">/</span><span class="n">fields</span><span class="s2">" | jq '. | to_entries[] | .key' -r | paste -sd "</span><span class="p">,</span><span class="s2">" -)"</span> <span class="p">\</span>
  <span class="o">-</span><span class="no">H</span> <span class="s2">"X-Auth-Email: $AUTH_EMAIL"</span> <span class="p">\</span>
  <span class="o">-</span><span class="no">H</span> <span class="s2">"X-Auth-Key: $API_KEY"</span> <span class="p">\</span>
  <span class="o">-</span><span class="no">H</span> <span class="s2">"Content-Type: application/json"</span><span class="p">;</span></code></pre></figure>

<p>Next step is to set cronjob to run this bash every <code class="highlighter-rouge">INTERVAL</code> time then the raw logs will be saved in <code class="highlighter-rouge">$time.json</code> format. Remember the size limit of each file is 1GB so if you have really a lot of requests coming through your Cloudflare zone, you may need to shorten <code class="highlighter-rouge">INTERVAL</code> or selectively log specific fields instead of logging everything. This way you can have your logs saved, the next step will be how to utilize and visualize them.</p>

<p>If you are familiar with one of the storages: Google Cloud Storage, AWS S3, Microsoft Azure, or if your SIEM is even Sumo Logic, please don’t follow this bash and go straight ahead to Logpush. More intuitive and simple. More read here: <a href="https://developers.cloudflare.com/logs/logpush/">Cloudflare Logpush</a></p>

<p>This guidance is more of a workaround for the ENT users don’t have those storages but still need to pull logs to their custom endpoints.</p>

:ET